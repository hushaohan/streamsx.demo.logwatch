namespace com.ibm.streamsx.demo.logwatch.language;

rstring flatten(list<rstring> lst)
{
    mutable rstring str = "";
    for (rstring e in lst) {
        str += e + " ";
    }
    return str;
}

composite LogWatch {
    type
        LogLine = timestamp time, rstring hostname, rstring service, rstring message;
        FailureRecord = timestamp time, rstring host, rstring user;
        SuccessRecord = timestamp time, rstring user;
        FailureSummary = timestamp minTime, timestamp maxTime, rstring host, rstring user, int32 numFailures;
        BreachRecord = timestamp time, rstring host, rstring user;

    graph
        stream<rstring line> RawLines = FileSource() {
            param file: "messages_broken.gz";
                  format: line;
                  compression: gzip;
        }

        stream<LogLine> ParsedLines = Custom(RawLines) {
            logic onTuple RawLines: {
                list<rstring> tokens = tokenize(line, " ", false);
                timestamp t = timeStringtoTimestamp(tokens[1] + "-" + upper(tokens[0]) + "-2011", tokens[2] + ".0", true);

                submit({time = t, hostname = tokens[3], service = tokens[4], message = flatten(tokens[5:])}, ParsedLines);
            }
        }

        stream<LogLine> FailureLines = Filter(ParsedLines) {
            param filter : findFirst(message, "authentication failure") != -1;
        }

        stream<FailureRecord> ParsedFailures = Custom(FailureLines) {
            logic onTuple FailureLines: {
                list<rstring> tokens = tokenize(message, " ", false);
                submit({
                    time = time,
                    host = tokens[7][6:],
                    user = size(tokens) > 8 ? tokens[8][5:] : ""
                }, ParsedFailures);
            }
        }

        stream<FailureSummary> FailuresSummaries = Aggregate(ParsedFailures) {
            window ParsedFailures: tumbling, count(5);
            param groupBy: host, user;
            output FailuresSummaries: minTime = Min(time), maxTime = Max(time), numFailures = Count();
        }

        stream<LogLine> SuccessLines = Filter(ParsedLines) {
            param filter : findFirst(message, "session opened") != -1;
        }

        stream<SuccessRecord> ParsedSuccesses = Custom(SuccessLines) {
            logic onTuple SuccessLines: {
                list<rstring> tokens = tokenize(message, " ", false);
                submit({
                    time = time,
                    user = tokens[4]
                }, ParsedSuccesses);
            }
        }

        stream<BreachRecord> BreachRecords = Join(FailuresSummaries; ParsedSuccesses) {
            window
                FailuresSummaries: sliding, count(1);
                ParsedSuccesses: sliding, count(1);
            param
                match: FailuresSummaries.numFailures == 5 && FailuresSummaries.user == ParsedSuccesses.user && diffAsSecs(ParsedSuccesses.time, FailuresSummaries.maxTime) < 60f;
            output
                BreachRecords: time = ParsedSuccesses.time, host = FailuresSummaries.host, user = ParsedSuccesses.user;
        }

        stream<BreachRecord> BreachRecordsDeduped = DeDuplicate(BreachRecords) {
            param
                key: time, host, user;
        }

        () as FailuresOutput = FileSink(ParsedFailures) {
            param file: "Failures.txt";
                  format: txt;
        }

        () as FailuresSummariesOutput = FileSink(FailuresSummaries) {
            param file: "FailuresSummaries.txt";
                  format: txt;
        }

        () as SuccessesOutput = FileSink(ParsedSuccesses) {
            param file: "Successes.txt";
                  format: txt;
        }

        () as BreachesOutput = FileSink(BreachRecordsDeduped) {
            param file: "BreachesDeduped.txt";
                  format: txt;
        }
}
